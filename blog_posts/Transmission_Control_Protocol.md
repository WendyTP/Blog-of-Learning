## Transmission Control Protocol (TCP)

The Transmission Control Protocol (TCP) is one of the corner-stones of the Internet. One of the key characteristics of this protocol is the fact that it provides reliable data transfer.

It provides an abstraction of reliable network communication on top of an unreliable channel. This abstraction hides much of the complexity of reliable network communication from the application layer: **data integrity, de-duplication, in-order delivery, and retransmission of lost data.**

The services (reliability) that TCP provides makes it the protocol of choice for many networked applications. The flip-side of the benefits that TCP provides are the performance challenges that come with its complexity. 

To balance this impact on performance, TPC provides mechanisms for **flow control** and **congestion avoidance**.

### TCP Segments

Along with reliability, TCP also provides data encapsulation and multiplexing, which are achieved through the use of TCP Segments.

Segments are the Protocol Data Unit (PDU) fo TCP. The data (the entire PDU) from the application layer is encapsulated into the payload of Segment.

![Simple diagram of TCP segment with header and payload](https://da77jsbdz4r05.cloudfront.net/images/ls170/transport-layer-tcp-segment.png)

#### TCP Segment header:

A TCP Segment header contains a number of different fields. 

**Source Port** and **Destination Port** provide the multiplexing capability of the protocol. 

Most of the other header fields are related to the way that TCP implements reliable data transfer.

A typical TCP header would look like this:

![Diagram of TCP segment header](https://da77jsbdz4r05.cloudfront.net/images/ls170/transport-tcp-segment-header.png)

(*Note: There are a number of different TCP variants, and the exact header fields they contain will vary slightly. Most of these variants will at a minimum contain the fields shown in the above diagram.)

Some of the more important fields in the header in terms of implementing reliability are:

* **CHECKSUM**: The Checksum provides the Error Detection aspect of TCP reliability. 

  It is an error checking value generated by the sender using an algorithm. The receiver generates a value using the same algorithm and if it doesn't match, it drops the Segment. Checksum is also implemented in other PDUs at other network layers such as IP Packets. Having a Checksum at the Transport Layer does render Checksums at lower layers redundant to a certain extent. IPv6 headers don't include a Checksum for this reason, though this is done with a requirement that a Checksum is used at the Transport Layer.

* **SEQUENCE NUMBER** and **ACKNOWLEDGEMENT NUMBER**: these two fields are used together to provide for the other elements of TCP reliability such as In-order Delivery, Handling Data Loss, and Handling Duplication. The precise way in which TCP uses these fields is essentially a more complex version of the simplified example of the Reliable Protocol constructed earlier.

* **WINDOW SIZE**:  The WINDOW SIZE field is related to Flow Control

* **Flag fields:** The flag fields are one-bit boolean fields. `URG`, `PSH`, etc are related to how the data contained in the Segment should be treated in terms of its importance or urgency. The `SYN`, `ACK`, `FIN`, and `RST` flags are used to establish and end a TCP connection, as well as manage the state of that connection. (The `SYN` and `ACK` flags are used in the Three-way Handshake; The `FIN` flag is used in the Four-way Handshake, for terminating connections.)

### TCP Connections

TCP is a connection-oriented protocol, it does **not** start sending application data  **until a connection has been established** between application processes.

TCP uses a **Three-way Handshake** to establish a connection.

Below is a simplified version of the Three-way Handshake process:

![Simple diagram of three-way TCP handshake](https://da77jsbdz4r05.cloudfront.net/images/ls170/transport-tcp-thre-way-handshake.png)

* The sender sends a SYN message (a TCP Segment with the `SYN` flag set to `1`)
* Upon receiving this SYN message, the receiver sends back a SYN ACK message (a TCP Segment with the `SYN` and `ACK` flags set to `1`)
* Upon receiving the SYN ACK, the sender then sends an `ACK` (a TCP Segment with the `ACK` flag set to `1`)

Upon sending the ACK, the sender can immediately start sending application data. The receiver must wait until it has received the ACK before it can send any data back to the sender.

 One of the main reasons for this process is to synchronise (`SYN`) the sequence numbers that will be used during the connection.

Part of the purposes of using these flags is to manage the **connection state**. According to  [RFC793](https://www.ietf.org/rfc/rfc793.txt):

â€‹	*A connection progresses through a series of states during its lifetime. The states are: LISTEN, SYN-SENT, SYN-RECEIVED, ESTABLISHED, FIN-WAIT-1, FIN-WAIT-2, CLOSE-WAIT, CLOSING, LAST-ACK, TIME-WAIT, and the fictional state CLOSED. CLOSED is fictional because it represents the state when there is no TCB, and therefore, no connection*.

Most of the time the state we are most concerned with is `ESTABLISHED`, and also `LISTEN` on the server side. The other states are related to the establishment and termination of connections.

**Three-way Handshake to Establish a Connection, with Connection States**:

| Client Start State | Client Action                                                | Client End State | Server Start State | Server Action                                                | Server End State |
| ------------------ | ------------------------------------------------------------ | ---------------- | ------------------ | ------------------------------------------------------------ | ---------------- |
| `CLOSED`           | Sends a `SYN`Segment                                         | `SYN-SENT`       | `LISTEN`           | Waits for a connection request                               | -                |
| `SYN-SENT`         | Waits to receive an ACK to the SYN it sent, as well as the server's `SYN` | `SYN-SENT`       | `LISTEN`           | Sends a SYN ACK Segment which serves as both it's SYN and an ACK for the client's SYN | `SYN-RECEIVED`   |
| `SYN-SENT`         | Receives the SYN ACK Segment sent by the server, and sends an ACK in response. The client is now finished with the connection establishment process | `ESTABLISHED`    | `SYN-RECEIVED`     | Waits for an ACK for the SYN it just sent                    | -                |
| `ESTABLISHED`      | Ready for data transfer. Can start sending application data. | `ESTABLISHED`    | `SYN-RECEIVED`     | Receives the ACK sent in response to its SYN. The server is now finished with the connection establishment process. | `ESTABLISHED`    |

There is a certain amount of complexity involved in the way how TCP manages connection state, especially at the initial establishment of a connection, where a key characteristic of the process is that **the sender cannot send any application data until after it has sent the `ACK` Segment**.

This, however, results in an entire *round-trip latency* before any application data can be exchanged. Since this hand-shake process occurs every time a TCP connection is made, this clearly has an impact on any application which uses TCP at the transport layer.

![Diagram of three-way TCP handshake, with data being sent after the ACK](https://da77jsbdz4r05.cloudfront.net/images/ls170/transport-tcp-thre-way-handshake-data-delay.png)

TCP involves a lot of overhead in terms of establishing connections, and providing reliability through the retransmission of lost data. 

In order to mitigate against this additional overhead, it is important that the actual functioning of data transfer when using the protocol occurs as efficiently as possible. 

In order to help facilitate efficient data transfer **after** a connection is established, TCP provides mechanisms for flow control and congestion avoidance.

### Flow Control

Flow control is a mechanism to prevent the sender from overwhelming the receiver with too much data at once. 

The receiver will only be able to process a certain amount of data in a particular time-frame. **Data awaiting processing is stored in a 'buffer'**. The buffer size will depend on the amount of memory allocated according to the configuration of the OS and the physical resources available.

Each side of a connection can let the other side know **the amount of data that it is willing to accept** via the **WINDOW field** of the TCP header. This number is dynamic, and can change during the course of a connection. If the receiver's buffer is getting full it can set a lower amount in the WINDOW field of a Segment it sends to the sender, the sender can then reduce the amount of data it sends accordingly.

Although flow control prevents the sender from overwhelming the receiver, it **doesn't** prevent either the sender or receiver from overwhelming the underlying network. For that task we need a different mechanism: Congestion Avoidance.

### Congestion Avoidance

Congestion Avoidance mechanism is created for preventing either the sender or receiver from overwhelming the underlying network.

Network Congestion is a situation that occurs when there is more data being transmitted on the network than there is network capacity to process and transmit the data. The excess data are simply dropped and therefore lost.

IP packets moving across the networks in a series of 'hops'. At each hop, the packet needs to be processed: the router at that hop runs a checksum on the packet data; it also needs to check the destination address and work out how to route the packet to the next hop on its journey to that destination. All of this processing takes time, and a router can only process so much data at once. Routers use a 'buffer' to store data that is awaiting processing, but if there is more data to be processed than can fit in the buffer, the buffer over-flows and those data packets are dropped.

These lost data are then retransmit by TCP (one of TCP's functionality). If there are a lot of data dropped at network layer, then there will be a lot of data in need of retransmitting, which make the communication inefficient. 

In order to keep retransmission to a minimum, TCP uses data loss as a feedback mechanism to detect and avoid network congestion ;  if lots of retransmissions are occurring, TCP takes this as a sign that the network is congested and reduces the size of the transmission window.

### Disadvantages of TCP

There is a latency overhead in establishing a TCP connection due to the handshake process. 

Another potential issue with using TCP is Head-of-Line (HOL) blocking.

Head-of-line blocking is a general networking concept, and isn't specific to TCP. In general terms it relates to how issues in delivering or processing one message in a sequence of messages can delay or 'block' the delivery or processing of the subsequent messages in the sequence.

With TCP, HOL blocking can occur as a result of the fact that TCP provides for **in-order delivery** of segments. Although this in order delivery is one aspect of TCP's reliability, if one of the segments goes missing and needs to be retransmitted, the segments that come after it in the sequence can't be processed, and need to be buffered until the retransmission has occurred. This can lead to increased queuing delay which is one of the elements of latency.